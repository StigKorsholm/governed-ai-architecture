# ADR-006: Treat LLM Outputs as Proposals Gated by Deterministic Validation

> **Status:** ✅ Accepted  
> **Date:** 2025-12-22  
> **Triggered By:** ADR-000 (consequence: "AI outputs cannot be trusted without enforcement")  
> **Triggers:** ADR-007, ADR-010, ADR-015

---

## Summary

* **Decision:** Every LLM-generated output must be treated as a proposal. Proposals must be structured (schema-compliant), validated against deterministic rules, and gated before they can progress to the next phase.
* **Chosen approach:** Multi-layer validation (schema → invariant → domain), explicit failure semantics, validators as first-class product code.
* **Why:** LLM confidence is not reliable. Trust emerges only from validator-backed signals, not model self-reporting. Without validation gates, errors propagate silently and compound.
* **Scope:** This ADR covers the philosophy and validation framework. Specific validators are implementation details.

---

## Context

Large language models do not produce truth. They produce **proposals**.

The distinction matters because:
- LLMs optimize for **plausibility**, not correctness
- Self-reported confidence **correlates poorly** with accuracy
- "Sounds right" is not acceptable in regulated environments
- Errors are **silent** — wrong outputs look exactly like right outputs

---

## Decision Drivers

1. **Trustworthiness** — Must detect incorrect outputs before they propagate
2. **Scalability** — Must filter automatically; human review is finite
3. **Auditability** — Must prove validation occurred
4. **Determinism** — Same input must produce same validation result
5. **Fail-fast** — Must stop bad outputs early

---

## Decision

We will treat **LLM outputs as proposals** gated by **deterministic validation**:

### 1. Every output is validated

| Layer | Checks |
|-------|--------|
| **Schema** | Structure, types, required fields |
| **Invariant** | Graph relationship rules |
| **Domain** | Business rules, reference data |
| **Reconciliation** | Completeness checks |

### 2. Explicit failure semantics

| Severity | Behavior |
|----------|----------|
| **FAIL** | Output rejected, phase cannot complete |
| **STOP** | Pipeline halts, requires human intervention |
| **WARN** | Output accepted, flagged for review |

### 3. Validators are first-class product code

Validators are **architecture components** with explicit contracts, version control, and tests.

---

## Decision Rationale

> Without deterministic enforcement, AI-generated artifacts become persuasive but unverifiable opinions.

---

## Consequences

### Architectural Implications

| Consequence | Triggers ADR |
|-------------|--------------|
| We must define graph invariants | ADR-007 |
| Confidence must be derived from validation | ADR-010 |
| Diagrams must come from validated graph | ADR-015 |

### Positive Consequences

- Higher trust in outputs
- Confidence becomes operationally meaningful
- Review work is appropriately prioritized
- Failures caught early

### Negative Consequences

- More engineering work upfront
- Validators become product code requiring maintenance

---

## References

- **LinkedIn Article:** [Why Trustworthy AI Is an Architecture Problem, Not a Model Problem](https://www.linkedin.com/pulse/why-trustworthy-ai-architecture-problem-model-stig-pedersen-korsholm-wmlje) (2026-01-01)
- **Related ADRs:** ADR-000 (root), ADR-007 (invariants), ADR-010 (confidence)
